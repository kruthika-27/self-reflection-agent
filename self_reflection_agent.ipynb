{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a72a908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from typing import List, TypedDict, Annotated, Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "import json\n",
    "from langgraph.types import interrupt, Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b664b6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ec2dcc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    current_score: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f1601926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM.\n",
    "# Ensure you have authenticated your gcloud CLI using 'gcloud auth application-default login'\n",
    "# and set a quota project using 'gcloud auth application-default set-quota-project YOUR_PROJECT_ID'.\n",
    "# Using 'gemini-pro' as a stable and widely available model.\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.0) # Lower temperature for more consistent output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1e967fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the chatbot node function.\n",
    "# This function will interact with the LLM to get grammar corrections and scores.\n",
    "def chatbot(state: State) -> State | Literal[END]:\n",
    "    \"\"\"\n",
    "    Processes the user's message, sends it to the LLM for grammar correction and scoring,\n",
    "    and updates the state with the corrected output and score.\n",
    "    \"\"\"\n",
    "    # Get the content of the last human message from the state.\n",
    "    # We assume the last message added to the 'messages' list is the user's input.\n",
    "    user_message = state[\"messages\"][-1].content\n",
    "\n",
    "    # Construct a detailed prompt for the LLM.\n",
    "    # The prompt instructs the LLM to return a JSON object with specific keys:\n",
    "    # 'corrected_sentence' and 'score'. This makes parsing the response reliable.\n",
    "    prompt = f\"\"\"You are a highly accurate grammar correction and scoring assistant.\n",
    "    Your task is to:\n",
    "    1. Grammatically correct the provided sentence, ensuring it is natural and fluent.\n",
    "    2. Assign a grammatical score to the *corrected* sentence. The score must be a float between 0.0 and 1.0, where 1.0 indicates perfect grammatical correctness and 0.0 indicates completely incorrect grammar. The score should reflect the grammatical quality of the *output* sentence.\n",
    "    3. Make only one correction at once in one iteartion.\n",
    "\n",
    "    Respond ONLY with a JSON object. Do not include any other text or explanation.\n",
    "    The JSON object must have the following two keys:\n",
    "    - `corrected_sentence`: The grammatically corrected version of the input sentence.\n",
    "    - `score`: A float (e.g., 0.95, 1.0) representing the grammatical score of the corrected sentence.\n",
    "\n",
    "    Example Input: 'He go to school.'\n",
    "    Example Output:\n",
    "    {{\n",
    "    \"corrected_sentence\": \"He goes to school.\",\n",
    "    \"score\": 0.98\n",
    "    }}\n",
    "\n",
    "    Example Input: 'The cat sits on the mat.'\n",
    "    Example Output:\n",
    "    {{\n",
    "    \"corrected_sentence\": \"The cat sits on the mat.\",\n",
    "    \"score\": 1.0\n",
    "    }}\n",
    "\n",
    "    Input sentence to correct and score: '{user_message}'\n",
    "    Don't include the json formatting that is \n",
    "    ```json\n",
    "    ```\"\"\"\n",
    "\n",
    "    # Invoke the LLM with the crafted prompt.\n",
    "    try:\n",
    "        raw_response = llm.invoke(prompt).content\n",
    "        # Attempt to parse the LLM's response as a JSON object.\n",
    "        response_data = json.loads(raw_response)\n",
    "        \n",
    "        # Extract the corrected sentence and score from the parsed JSON.\n",
    "        # Provide fallback values in case keys are missing (though the prompt aims to prevent this).\n",
    "        corrected_sentence = response_data.get(\"corrected_sentence\", user_message)\n",
    "        score = float(response_data.get(\"score\", 0.0)) # Ensure score is a float\n",
    "    except json.JSONDecodeError:\n",
    "        # Handle cases where the LLM does not return valid JSON.\n",
    "        print(f\"Warning: Could not parse LLM response as JSON. Raw response: {raw_response}\")\n",
    "        corrected_sentence = f\"Error: Could not process grammar. Original input: '{user_message}'. Please try rephrasing.\"\n",
    "        score = 0.0 # Set score to 0 to ensure re-processing if JSON parsing fails\n",
    "    except Exception as e:\n",
    "        # Handle any other unexpected errors during LLM invocation or data extraction.\n",
    "        print(f\"An unexpected error occurred during LLM invocation: {e}\")\n",
    "        corrected_sentence = f\"Error: An unexpected error occurred. Original input: '{user_message}'. Please try again.\"\n",
    "        score = 0.0\n",
    "\n",
    "    # Format the output string as requested by the user.\n",
    "    formatted_output = f\"Output: {corrected_sentence}\\nScore: {score:.2f}\" # Format score to 2 decimal places\n",
    "\n",
    "    # Return the updated state.\n",
    "    # 'messages' is updated with the AIMessage containing the formatted output.\n",
    "    # 'current_score' is updated with the score extracted from the LLM's response.\n",
    "    print(state)\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=corrected_sentence)],\n",
    "        \"current_score\": score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b58ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the conditional function that determines the next step in the graph.\n",
    "def should_continue(state: State) -> Literal[\"chatbot\"] | Literal[END]:\n",
    "    \"\"\"\n",
    "    Checks the current_score in the state.\n",
    "    If the score is 0.95 or higher, the process ends.\n",
    "    Otherwise, it loops back to the 'chatbot' node for another attempt.\n",
    "    \"\"\"\n",
    "    score = state.get(\"current_score\", 0.0) # Get the current score, defaulting to 0.0 if not found\n",
    "    \n",
    "    # Define the threshold for stopping the loop.\n",
    "    score_threshold = 0.95\n",
    "    \n",
    "\n",
    "    if score >= score_threshold:\n",
    "        print(f\"Grammatical score {score:.2f} >= {score_threshold}. Ending process.\")\n",
    "        return END # End the graph execution\n",
    "    else:\n",
    "        print(f\"Grammatical score {score:.2f} < {score_threshold}. Re-processing...\")\n",
    "        return \"chatbot\" # Loop back to the chatbot node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8e4058b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x70b81d1e4b10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the LangGraph.\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Add the 'chatbot' node to the graph.\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# Set the entry point of the graph to the 'chatbot' node.\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# Add a conditional edge from the 'chatbot' node.\n",
    "# The 'should_continue' function will be called after 'chatbot' executes.\n",
    "# Its return value ('chatbot' or END) will dictate the next transition.\n",
    "builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"chatbot\": \"chatbot\", # If should_continue returns \"chatbot\", transition to \"chatbot\" node\n",
    "        END: END              # If should_continue returns END, terminate the graph\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c3b0e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the graph into an executable application.\n",
    "app = builder.compile()\n",
    "\n",
    "# --- Example Usage ---\n",
    "# You can test the chatbot by streaming inputs through the compiled app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8208e077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55455df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Testing with 'He go a to school..' ---\n",
      "{'messages': [HumanMessage(content='He was is a kitten.', additional_kwargs={}, response_metadata={}, id='4523cd1a-e011-41b8-aa0b-cc5b56b4274a')]}\n",
      "Grammatical score 1.00 >= 0.95. Ending process.\n",
      "{'chatbot': {'messages': [AIMessage(content='He is a kitten.', additional_kwargs={}, response_metadata={}, id='addd2d50-2b72-47b9-82e6-0d4f014216ad')], 'current_score': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "# You can test the chatbot by streaming inputs through the compiled app.\n",
    "\n",
    "# Example 1: Sentence that might need correction and iterative improvement\n",
    "# Example 1: Sentence that might need correction and iterative improvement\n",
    "print(\"--- Testing with 'He go a to school..' ---\")\n",
    "inputs1 = {\"messages\": [HumanMessage(content=\"He was is a kitten.\")]}\n",
    "for s in app.stream(inputs1):\n",
    "    print(s)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e80501c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Me walk to store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='301de33a-0eb4-48ef-8455-21dc82230711')]}\n",
      "Grammatical score 0.15 < 0.95. Re-processing...\n",
      "I walk to store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.\n",
      "{'messages': [HumanMessage(content='Me walk to store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='301de33a-0eb4-48ef-8455-21dc82230711'), AIMessage(content='I walk to store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='cb0d7587-50f2-46fc-9441-4cfd6b0adf00')], 'current_score': 0.15}\n",
      "Grammatical score 0.40 < 0.95. Re-processing...\n",
      "I walked to the store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.\n",
      "{'messages': [HumanMessage(content='Me walk to store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='301de33a-0eb4-48ef-8455-21dc82230711'), AIMessage(content='I walk to store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='cb0d7587-50f2-46fc-9441-4cfd6b0adf00'), AIMessage(content='I walked to the store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='395f9554-d406-492d-9a7a-5364ff739518')], 'current_score': 0.4}\n",
      "Grammatical score 0.40 < 0.95. Re-processing...\n",
      "I walked to the store and bought an apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.\n",
      "{'messages': [HumanMessage(content='Me walk to store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='301de33a-0eb4-48ef-8455-21dc82230711'), AIMessage(content='I walk to store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='cb0d7587-50f2-46fc-9441-4cfd6b0adf00'), AIMessage(content='I walked to the store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='395f9554-d406-492d-9a7a-5364ff739518'), AIMessage(content='I walked to the store and bought an apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='2601badf-7164-4eb2-bc62-0c6c5d00cbe2')], 'current_score': 0.4}\n",
      "Grammatical score 0.60 < 0.95. Re-processing...\n",
      "I walked to the store and bought an apple. Then I saw a cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.\n",
      "{'messages': [HumanMessage(content='Me walk to store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='301de33a-0eb4-48ef-8455-21dc82230711'), AIMessage(content='I walk to store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='cb0d7587-50f2-46fc-9441-4cfd6b0adf00'), AIMessage(content='I walked to the store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='395f9554-d406-492d-9a7a-5364ff739518'), AIMessage(content='I walked to the store and bought an apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='2601badf-7164-4eb2-bc62-0c6c5d00cbe2'), AIMessage(content='I walked to the store and bought an apple. Then I saw a cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='805f4fa4-4446-46d1-99e4-e25091c59514')], 'current_score': 0.6}\n",
      "Grammatical score 0.55 < 0.95. Re-processing...\n",
      "I walked to the store and bought an apple. Then I saw a cat, it was black. Cat ran fast, I chasing. My friend come, we laugh loud. Them was good time.\n",
      "{'messages': [HumanMessage(content='Me walk to store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='301de33a-0eb4-48ef-8455-21dc82230711'), AIMessage(content='I walk to store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='cb0d7587-50f2-46fc-9441-4cfd6b0adf00'), AIMessage(content='I walked to the store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='395f9554-d406-492d-9a7a-5364ff739518'), AIMessage(content='I walked to the store and bought an apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='2601badf-7164-4eb2-bc62-0c6c5d00cbe2'), AIMessage(content='I walked to the store and bought an apple. Then I saw a cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='805f4fa4-4446-46d1-99e4-e25091c59514'), AIMessage(content='I walked to the store and bought an apple. Then I saw a cat, it was black. Cat ran fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='fe5f1dcd-8c4e-4841-8cc2-201ac13a958e')], 'current_score': 0.55}\n",
      "Grammatical score 0.68 < 0.95. Re-processing...\n",
      "I walked to the store and bought an apple. Then I saw a cat, it was black. Cat ran fast, I was chasing. My friend come, we laugh loud. Them was good time.\n",
      "{'messages': [HumanMessage(content='Me walk to store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='301de33a-0eb4-48ef-8455-21dc82230711'), AIMessage(content='I walk to store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='cb0d7587-50f2-46fc-9441-4cfd6b0adf00'), AIMessage(content='I walked to the store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='395f9554-d406-492d-9a7a-5364ff739518'), AIMessage(content='I walked to the store and bought an apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='2601badf-7164-4eb2-bc62-0c6c5d00cbe2'), AIMessage(content='I walked to the store and bought an apple. Then I saw a cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='805f4fa4-4446-46d1-99e4-e25091c59514'), AIMessage(content='I walked to the store and bought an apple. Then I saw a cat, it was black. Cat ran fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='fe5f1dcd-8c4e-4841-8cc2-201ac13a958e'), AIMessage(content='I walked to the store and bought an apple. Then I saw a cat, it was black. Cat ran fast, I was chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='bb5066ad-3792-442b-863d-bb1d9f232d31')], 'current_score': 0.68}\n",
      "Grammatical score 0.78 < 0.95. Re-processing...\n",
      "I walked to the store and bought an apple. Then I saw a cat. It was black. Cat ran fast, I was chasing. My friend come, we laugh loud. Them was good time.\n",
      "{'messages': [HumanMessage(content='Me walk to store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='301de33a-0eb4-48ef-8455-21dc82230711'), AIMessage(content='I walk to store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='cb0d7587-50f2-46fc-9441-4cfd6b0adf00'), AIMessage(content='I walked to the store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='395f9554-d406-492d-9a7a-5364ff739518'), AIMessage(content='I walked to the store and bought an apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='2601badf-7164-4eb2-bc62-0c6c5d00cbe2'), AIMessage(content='I walked to the store and bought an apple. Then I saw a cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='805f4fa4-4446-46d1-99e4-e25091c59514'), AIMessage(content='I walked to the store and bought an apple. Then I saw a cat, it was black. Cat ran fast, I chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='fe5f1dcd-8c4e-4841-8cc2-201ac13a958e'), AIMessage(content='I walked to the store and bought an apple. Then I saw a cat, it was black. Cat ran fast, I was chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='bb5066ad-3792-442b-863d-bb1d9f232d31'), AIMessage(content='I walked to the store and bought an apple. Then I saw a cat. It was black. Cat ran fast, I was chasing. My friend come, we laugh loud. Them was good time.', additional_kwargs={}, response_metadata={}, id='0e4a1e79-04bf-44fc-8b86-13143fc12924')], 'current_score': 0.78}\n",
      "Grammatical score 0.55 < 0.95. Re-processing...\n",
      "I walked to the store and bought an apple. Then I saw a cat. It was black. The cat ran fast, I was chasing. My friend come, we laugh loud. Them was good time.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs1 \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMe walk to store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.\u001b[39m\u001b[38;5;124m\"\u001b[39m)]}\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchatbot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2534\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2532\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[1;32m   2533\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 2534\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2539\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   2541\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmpty\u001b[49m\n\u001b[1;32m   2543\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2544\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/langgraph/pregel/runner.py:162\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    160\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/langgraph/pregel/retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/langgraph/utils/runnable.py:623\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m--> 623\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/langgraph/utils/runnable.py:377\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 377\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[37], line 47\u001b[0m, in \u001b[0;36mchatbot\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Invoke the LLM with the crafted prompt.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     raw_response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Attempt to parse the LLM's response as a JSON object.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     response_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(raw_response)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:1334\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI.invoke\u001b[0;34m(self, input, config, code_execution, stop, **kwargs)\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1330\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1331\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTools are already defined.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_execution tool can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be defined\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1332\u001b[0m         )\n\u001b[0;32m-> 1334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:378\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    374\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    375\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    377\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 378\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    388\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:963\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    961\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    962\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:782\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    781\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 782\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m         )\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1028\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1028\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1032\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:1441\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate\u001b[39m(\n\u001b[1;32m   1415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1416\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1428\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m   1429\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m   1430\u001b[0m         messages,\n\u001b[1;32m   1431\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1439\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1440\u001b[0m     )\n\u001b[0;32m-> 1441\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1443\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:231\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    224\u001b[0m params \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    225\u001b[0m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (request \u001b[38;5;241m:=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[1;32m    230\u001b[0m )\n\u001b[0;32m--> 231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/tenacity/__init__.py:332\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(\n\u001b[1;32m    329\u001b[0m     f, functools\u001b[38;5;241m.\u001b[39mWRAPPER_ASSIGNMENTS \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__defaults__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__kwdefaults__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    330\u001b[0m )\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/tenacity/__init__.py:469\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 469\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    471\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/tenacity/__init__.py:370\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    368\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 370\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/tenacity/__init__.py:392\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[0;32m--> 392\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/tenacity/__init__.py:472\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 472\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    474\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:206\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_chat_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mFailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:868\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    867\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:294\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    293\u001b[0m )\n\u001b[0;32m--> 294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:147\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    149\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/google/api_core/timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[1;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/grpc/_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    270\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/grpc/_interceptor.py:329\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _FailureOutcome(exception, sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m--> 329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interceptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_unary_unary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontinuation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mresult(), call\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py:78\u001b[0m, in \u001b[0;36m_LoggingClientInterceptor.intercept_unary_unary\u001b[0;34m(self, continuation, client_call_details, request)\u001b[0m\n\u001b[1;32m     64\u001b[0m     grpc_request \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpayload\u001b[39m\u001b[38;5;124m\"\u001b[39m: request_payload,\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequestMethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrpc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(request_metadata),\n\u001b[1;32m     68\u001b[0m     }\n\u001b[1;32m     69\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_call_details\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     71\u001b[0m         extra\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m         },\n\u001b[1;32m     77\u001b[0m     )\n\u001b[0;32m---> 78\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcontinuation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logging_enabled:  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     response_metadata \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtrailing_metadata()\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/grpc/_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    306\u001b[0m (\n\u001b[1;32m    307\u001b[0m     new_method,\n\u001b[1;32m    308\u001b[0m     new_timeout,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m     new_compression,\n\u001b[1;32m    313\u001b[0m ) \u001b[38;5;241m=\u001b[39m _unwrap_client_call_details(new_details, client_call_details)\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/grpc/_channel.py:1195\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwith_call\u001b[39m(\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1185\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1190\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1191\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, grpc\u001b[38;5;241m.\u001b[39mCall]:\n\u001b[1;32m   1192\u001b[0m     (\n\u001b[1;32m   1193\u001b[0m         state,\n\u001b[1;32m   1194\u001b[0m         call,\n\u001b[0;32m-> 1195\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/grpc/_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[1;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[1;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[0;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "inputs1 = {\"messages\": [HumanMessage(content=\"Me walk to store, buy apple. Then I seen cat, it was black. Cat run fast, I chasing. My friend come, we laugh loud. Them was good time.\")]}\n",
    "for s in app.stream(inputs1):\n",
    "    print(s['chatbot']['messages'][0].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358049ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
